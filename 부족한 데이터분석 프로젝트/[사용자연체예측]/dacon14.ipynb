{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport glob\nimport pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import OneHotEncoder\nimport random\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/daconcard/open/train.csv')\ntest=pd.read_csv('/kaggle/input/daconcard/open/test.csv')\nsubmit=pd.read_csv('/kaggle/input/daconcard/open/sample_submission.csv')","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv('train.csv')\ntrain = train.drop(['index'], axis=1)\ntrain.fillna('NAN', inplace=True) \ntrain['occyp_type'].loc[(train.occyp_type == 'NAN')&(train.DAYS_EMPLOYED > 0)]='Unemployed'\n\ntrain.fillna('NAN', inplace=True) \ntrain['occyp_type'].loc[(train.occyp_type == 'NAN')&(train.DAYS_EMPLOYED < 0)]='Missing'\n\n# test = pd.read_csv('test.csv')\ntest = test.drop(['index'], axis=1)\ntest.fillna('NAN', inplace=True)\ntest['occyp_type'].loc[(test.occyp_type == 'NAN')&(test.DAYS_EMPLOYED > 0)]='Unemployed'\ntest['occyp_type'].loc[(test.occyp_type == 'NAN')&(test.DAYS_EMPLOYED < 0)]='Missing'","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"object_col = []\nfor col in train.columns:\n    if train[col].dtype == 'object':\n        object_col.append(col)","metadata":{"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"enc = OneHotEncoder()\nenc.fit(train.loc[:,object_col])\n\ntrain_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n             columns=enc.get_feature_names(object_col))\ntrain.drop(object_col, axis=1, inplace=True)\ntrain = pd.concat([train, train_onehot_df], axis=1)","metadata":{"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n             columns=enc.get_feature_names(object_col))\ntest.drop(object_col, axis=1, inplace=True)\ntest = pd.concat([test, test_onehot_df], axis=1)","metadata":{"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfolds=[]\nfor train_idx, valid_idx in skf.split(train, train['credit']):\n    folds.append((train_idx, valid_idx))","metadata":{"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nlgb_models={}\nfor fold in range(5):\n    print(f'===================================={fold+1}============================================')\n    train_idx, valid_idx = folds[fold]\n    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n    \n    params={\n        'objective':'multiclass',\n        'random_state':71,\n        'n_estimators':1000\n    }\n    lgb_model = LGBMClassifier(**params)\n    lgb_model.fit(X_train,y_train,\n              eval_set=[(X_train, y_train),(X_test,y_test)],\n              eval_metric='multi_logloss',verbose=True,\n              early_stopping_rounds=10)\n    lgb_models[fold]=lgb_model\n    print(f'================================================================================\\n\\n')","metadata":{"scrolled":true,"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"====================================1============================================\nTraining until validation scores don't improve for 30 rounds\n[100]\ttraining's multi_logloss: 0.652377\tvalid_1's multi_logloss: 0.752522\n[200]\ttraining's multi_logloss: 0.56559\tvalid_1's multi_logloss: 0.737156\n[300]\ttraining's multi_logloss: 0.501921\tvalid_1's multi_logloss: 0.731843\nEarly stopping, best iteration is:\n[348]\ttraining's multi_logloss: 0.475822\tvalid_1's multi_logloss: 0.729304\n================================================================================\n\n\n====================================2============================================\nTraining until validation scores don't improve for 30 rounds\n[100]\ttraining's multi_logloss: 0.646476\tvalid_1's multi_logloss: 0.764955\n[200]\ttraining's multi_logloss: 0.560614\tvalid_1's multi_logloss: 0.751681\n[300]\ttraining's multi_logloss: 0.497532\tvalid_1's multi_logloss: 0.748007\nEarly stopping, best iteration is:\n[281]\ttraining's multi_logloss: 0.508566\tvalid_1's multi_logloss: 0.747717\n================================================================================\n\n\n====================================3============================================\nTraining until validation scores don't improve for 30 rounds\n[100]\ttraining's multi_logloss: 0.652042\tvalid_1's multi_logloss: 0.758665\n[200]\ttraining's multi_logloss: 0.560771\tvalid_1's multi_logloss: 0.743359\nEarly stopping, best iteration is:\n[246]\ttraining's multi_logloss: 0.529839\tvalid_1's multi_logloss: 0.74126\n================================================================================\n\n\n====================================4============================================\nTraining until validation scores don't improve for 30 rounds\n[100]\ttraining's multi_logloss: 0.648049\tvalid_1's multi_logloss: 0.755495\n[200]\ttraining's multi_logloss: 0.560137\tvalid_1's multi_logloss: 0.739883\n[300]\ttraining's multi_logloss: 0.497795\tvalid_1's multi_logloss: 0.734204\nEarly stopping, best iteration is:\n[309]\ttraining's multi_logloss: 0.493086\tvalid_1's multi_logloss: 0.733839\n================================================================================\n\n\n====================================5============================================\nTraining until validation scores don't improve for 30 rounds\n[100]\ttraining's multi_logloss: 0.650986\tvalid_1's multi_logloss: 0.755168\n[200]\ttraining's multi_logloss: 0.565819\tvalid_1's multi_logloss: 0.740535\n[300]\ttraining's multi_logloss: 0.502856\tvalid_1's multi_logloss: 0.736778\nEarly stopping, best iteration is:\n[323]\ttraining's multi_logloss: 0.490989\tvalid_1's multi_logloss: 0.736467\n================================================================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"xgb_models={}\nfor fold in range(5):\n    print(f'===================================={fold+1}============================================')\n    train_idx, valid_idx = folds[fold]\n    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n    params={\n    'objective':'multi:softprob',\n    'random_state':71,\n    'n_estimators':1000\n    }\n    model = XGBClassifier(**params)\n    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric = 'mlogloss',early_stopping_rounds=30, verbose=100)\n    xgb_models[fold]=model\n    print(f'================================================================================\\n\\n')","metadata":{"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"====================================1============================================\n[0]\tvalidation_0-mlogloss:0.97436\tvalidation_1-mlogloss:0.97758\n[100]\tvalidation_0-mlogloss:0.56747\tvalidation_1-mlogloss:0.73381\n[200]\tvalidation_0-mlogloss:0.44779\tvalidation_1-mlogloss:0.72234\n[211]\tvalidation_0-mlogloss:0.43764\tvalidation_1-mlogloss:0.72251\n================================================================================\n\n\n====================================2============================================\n[0]\tvalidation_0-mlogloss:0.97304\tvalidation_1-mlogloss:0.97925\n[100]\tvalidation_0-mlogloss:0.56072\tvalidation_1-mlogloss:0.74882\n[200]\tvalidation_0-mlogloss:0.44335\tvalidation_1-mlogloss:0.74027\n[235]\tvalidation_0-mlogloss:0.41306\tvalidation_1-mlogloss:0.74266\n================================================================================\n\n\n====================================3============================================\n[0]\tvalidation_0-mlogloss:0.97442\tvalidation_1-mlogloss:0.97858\n[100]\tvalidation_0-mlogloss:0.56273\tvalidation_1-mlogloss:0.74339\n[200]\tvalidation_0-mlogloss:0.44721\tvalidation_1-mlogloss:0.73763\n[205]\tvalidation_0-mlogloss:0.44174\tvalidation_1-mlogloss:0.73743\n================================================================================\n\n\n====================================4============================================\n[0]\tvalidation_0-mlogloss:0.97382\tvalidation_1-mlogloss:0.97803\n[100]\tvalidation_0-mlogloss:0.56483\tvalidation_1-mlogloss:0.73918\n[200]\tvalidation_0-mlogloss:0.44943\tvalidation_1-mlogloss:0.73279\n[219]\tvalidation_0-mlogloss:0.43177\tvalidation_1-mlogloss:0.73394\n================================================================================\n\n\n====================================5============================================\n[0]\tvalidation_0-mlogloss:0.97453\tvalidation_1-mlogloss:0.97726\n[100]\tvalidation_0-mlogloss:0.56257\tvalidation_1-mlogloss:0.73905\n[181]\tvalidation_0-mlogloss:0.46090\tvalidation_1-mlogloss:0.73424\n================================================================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"rf_models={}\nfor fold in range(5):\n    print(f'===================================={fold+1}============================================')\n    train_idx, valid_idx = folds[fold]\n    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n    params={'n_estimators':1000,'random_state':71,'criterion':'gini','verbose':1,'class_weight':'balanced','n_jobs':-1,'oob_score':True}\n    model=RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n    rf_models[fold]=model\n    print(f'================================================================================\\n\\n')","metadata":{"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"====================================1============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.5s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.9s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.6s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.5s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================2============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    6.2s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.7s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.4s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================3============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.9s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.6s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.4s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================4============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.7s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.7s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.9s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.6s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.4s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================5============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    6.0s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.5s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.4s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\nsvc_models={}\nfor fold in range(5):\n    print(f'===================================={fold+1}============================================')\n    train_idx, valid_idx = folds[fold]\n    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n    params={'gamma':'auto','probability':True,'random_state':71,'class_weight':'balanced','kernel':'poly','shrinking':True,'verbose':True}\n    svc_model=SVC(**params)\n    model.fit(X_train, y_train)\n    svc_models[fold]=model\n    print(f'================================================================================\\n\\n')","metadata":{"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"====================================1============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.8s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.4s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.1s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================2============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.8s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.3s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.3s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================3============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.5s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.9s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.6s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.3s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================4============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.5s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.7s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.5s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.2s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================5============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    5.9s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   10.5s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.2s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## extra tree\nfrom sklearn.ensemble import ExtraTreesClassifier\n\net_models={}\nfor fold in range(5):\n    print(f'===================================={fold+1}============================================')\n    train_idx, valid_idx = folds[fold]\n    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n    params={'n_estimators':1000,'random_state':71,\n            'criterion':'gini','verbose':1,\n            'class_weight':'balanced','n_jobs':-1,\n            'oob_score':True,'bootstrap':True}\n    model=ExtraTreesClassifier(**params)\n    model.fit(X_train, y_train)\n    et_models[fold]=model\n    print(f'================================================================================\\n\\n')","metadata":{"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"====================================1============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.1s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    4.8s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.8s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================2============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.2s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    4.8s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    8.6s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.9s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================3============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.0s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    4.7s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    8.4s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.7s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================4============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    1.9s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    4.5s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    8.2s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.4s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n====================================5============================================\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    2.0s\n[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    4.6s\n[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    8.3s\n[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.4s finished\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## catboost\nfrom catboost import CatBoostClassifier\n\ncat_models={}\nfor fold in range(5):\n    print(f'===================================={fold+1}============================================')\n    train_idx, valid_idx = folds[fold]\n    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n    params={\n        'objective':'MultiClass',\n        'eval_metric':'MultiClass',\n        'n_estimators':1000,\n        'random_state':71,\n        'auto_class_weights':'Balanced',\n        'boost_from_average':False  \n    }\n    cat = CatBoostClassifier(**params)\n    cat.fit(X_train, y_train, \n            eval_set=[(X_train, y_train),(X_valid, y_valid)], \n            early_stopping_rounds=30,\n            verbose=100)\n    cat_models[fold]=cat\n    print(f'================================================================================\\n\\n')","metadata":{"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"====================================1============================================\nLearning rate set to 0.114773\n0:\tlearn: 1.0895820\ttest: 1.0895820\ttest1: 1.0896573\tbest: 1.0896573 (0)\ttotal: 11.4ms\tremaining: 11.4s\n100:\tlearn: 0.9698670\ttest: 0.9698670\ttest1: 1.0136863\tbest: 1.0136863 (100)\ttotal: 1.07s\tremaining: 9.57s\n200:\tlearn: 0.9060488\ttest: 0.9060488\ttest1: 0.9892715\tbest: 0.9889748 (196)\ttotal: 2.14s\tremaining: 8.52s\n300:\tlearn: 0.8556618\ttest: 0.8556618\ttest1: 0.9741184\tbest: 0.9741184 (300)\ttotal: 3.19s\tremaining: 7.41s\n400:\tlearn: 0.8153924\ttest: 0.8153924\ttest1: 0.9653571\tbest: 0.9653334 (399)\ttotal: 4.25s\tremaining: 6.35s\n500:\tlearn: 0.7814837\ttest: 0.7814837\ttest1: 0.9594054\tbest: 0.9592936 (497)\ttotal: 5.32s\tremaining: 5.3s\n600:\tlearn: 0.7504801\ttest: 0.7504801\ttest1: 0.9537349\tbest: 0.9536191 (599)\ttotal: 6.36s\tremaining: 4.22s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.9514883775\nbestIteration = 645\n\nShrink model to first 646 iterations.\n================================================================================\n\n\n====================================2============================================\nLearning rate set to 0.114773\n0:\tlearn: 1.0886311\ttest: 1.0886311\ttest1: 1.0899498\tbest: 1.0899498 (0)\ttotal: 11.6ms\tremaining: 11.6s\n100:\tlearn: 0.9654256\ttest: 0.9654256\ttest1: 1.0191423\tbest: 1.0191423 (100)\ttotal: 1.1s\tremaining: 9.79s\n200:\tlearn: 0.8997776\ttest: 0.8997776\ttest1: 0.9991520\tbest: 0.9991520 (200)\ttotal: 2.18s\tremaining: 8.68s\n300:\tlearn: 0.8525919\ttest: 0.8525919\ttest1: 0.9875881\tbest: 0.9874853 (296)\ttotal: 3.27s\tremaining: 7.6s\n400:\tlearn: 0.8136242\ttest: 0.8136242\ttest1: 0.9781451\tbest: 0.9781451 (400)\ttotal: 4.34s\tremaining: 6.48s\n500:\tlearn: 0.7786788\ttest: 0.7786788\ttest1: 0.9735053\tbest: 0.9731996 (495)\ttotal: 5.42s\tremaining: 5.4s\n600:\tlearn: 0.7475585\ttest: 0.7475585\ttest1: 0.9677389\tbest: 0.9677389 (600)\ttotal: 6.48s\tremaining: 4.3s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.9668129818\nbestIteration = 643\n\nShrink model to first 644 iterations.\n================================================================================\n\n\n====================================3============================================\nLearning rate set to 0.114773\n0:\tlearn: 1.0896589\ttest: 1.0896589\ttest1: 1.0906821\tbest: 1.0906821 (0)\ttotal: 11.2ms\tremaining: 11.2s\n100:\tlearn: 0.9697334\ttest: 0.9697334\ttest1: 1.0196325\tbest: 1.0196325 (100)\ttotal: 1.05s\tremaining: 9.35s\n200:\tlearn: 0.9010360\ttest: 0.9010360\ttest1: 1.0000565\tbest: 1.0000565 (200)\ttotal: 2.08s\tremaining: 8.26s\n300:\tlearn: 0.8496441\ttest: 0.8496441\ttest1: 0.9884082\tbest: 0.9883348 (299)\ttotal: 3.09s\tremaining: 7.17s\n400:\tlearn: 0.8077736\ttest: 0.8077736\ttest1: 0.9811231\tbest: 0.9811231 (400)\ttotal: 4.15s\tremaining: 6.2s\n500:\tlearn: 0.7744466\ttest: 0.7744466\ttest1: 0.9784252\tbest: 0.9779469 (489)\ttotal: 5.28s\tremaining: 5.26s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.9777748238\nbestIteration = 515\n\nShrink model to first 516 iterations.\n================================================================================\n\n\n====================================4============================================\nLearning rate set to 0.114773\n0:\tlearn: 1.0888544\ttest: 1.0888544\ttest1: 1.0898035\tbest: 1.0898035 (0)\ttotal: 11.3ms\tremaining: 11.3s\n100:\tlearn: 0.9699341\ttest: 0.9699341\ttest1: 1.0232805\tbest: 1.0232805 (100)\ttotal: 1.01s\tremaining: 8.98s\n200:\tlearn: 0.9042148\ttest: 0.9042148\ttest1: 0.9993205\tbest: 0.9993205 (200)\ttotal: 1.98s\tremaining: 7.87s\n300:\tlearn: 0.8554251\ttest: 0.8554251\ttest1: 0.9851962\tbest: 0.9850279 (294)\ttotal: 2.97s\tremaining: 6.89s\n400:\tlearn: 0.8132705\ttest: 0.8132705\ttest1: 0.9735853\tbest: 0.9735046 (398)\ttotal: 3.98s\tremaining: 5.95s\n500:\tlearn: 0.7777657\ttest: 0.7777657\ttest1: 0.9671493\tbest: 0.9670020 (498)\ttotal: 5s\tremaining: 4.98s\n600:\tlearn: 0.7483581\ttest: 0.7483581\ttest1: 0.9640293\tbest: 0.9640293 (600)\ttotal: 6.08s\tremaining: 4.04s\n700:\tlearn: 0.7216177\ttest: 0.7216177\ttest1: 0.9606008\tbest: 0.9604642 (699)\ttotal: 7.15s\tremaining: 3.05s\n800:\tlearn: 0.6962549\ttest: 0.6962549\ttest1: 0.9579172\tbest: 0.9577125 (789)\ttotal: 8.22s\tremaining: 2.04s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.9572729933\nbestIteration = 812\n\nShrink model to first 813 iterations.\n================================================================================\n\n\n====================================5============================================\nLearning rate set to 0.114773\n0:\tlearn: 1.0897427\ttest: 1.0897427\ttest1: 1.0899943\tbest: 1.0899943 (0)\ttotal: 11.6ms\tremaining: 11.6s\n100:\tlearn: 0.9711639\ttest: 0.9711639\ttest1: 1.0166501\tbest: 1.0166501 (100)\ttotal: 1.04s\tremaining: 9.28s\n200:\tlearn: 0.9038311\ttest: 0.9038311\ttest1: 0.9932910\tbest: 0.9932910 (200)\ttotal: 2.09s\tremaining: 8.3s\n300:\tlearn: 0.8551407\ttest: 0.8551407\ttest1: 0.9834571\tbest: 0.9831664 (297)\ttotal: 3.08s\tremaining: 7.16s\n400:\tlearn: 0.8121489\ttest: 0.8121489\ttest1: 0.9751660\tbest: 0.9751660 (400)\ttotal: 4.1s\tremaining: 6.12s\n500:\tlearn: 0.7780128\ttest: 0.7780128\ttest1: 0.9694235\tbest: 0.9691904 (497)\ttotal: 5.13s\tremaining: 5.11s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.9660146274\nbestIteration = 563\n\nShrink model to first 564 iterations.\n================================================================================\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"submit.iloc[:,1:]=0\nfor fold in range(5):\n    submit.iloc[:,1:] += (lgb_models[fold].predict_proba(test)/30)\n    submit.iloc[:,1:] += (xgb_models[fold].predict_proba(test)/30)\n    submit.iloc[:,1:] += (svc_models[fold].predict_proba(test)/30)\n    submit.iloc[:,1:] += (rf_models[fold].predict_proba(test)/30)\n    submit.iloc[:,1:] += (et_models[fold].predict_proba(test)/30)\n    submit.iloc[:,1:] += (cat_models[fold].predict_proba(test)/30)\nsubmit.head()","metadata":{"trusted":true},"execution_count":116,"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.0s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.2s finished\n[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.1s finished\n","output_type":"stream"},{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"   index         0         1         2\n0  26457  0.065153  0.166709  0.768137\n1  26458  0.299807  0.247308  0.452884\n2  26459  0.087402  0.117350  0.795247\n3  26460  0.136295  0.108191  0.755514\n4  26461  0.111654  0.226443  0.661903","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26457</td>\n      <td>0.065153</td>\n      <td>0.166709</td>\n      <td>0.768137</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26458</td>\n      <td>0.299807</td>\n      <td>0.247308</td>\n      <td>0.452884</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26459</td>\n      <td>0.087402</td>\n      <td>0.117350</td>\n      <td>0.795247</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26460</td>\n      <td>0.136295</td>\n      <td>0.108191</td>\n      <td>0.755514</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26461</td>\n      <td>0.111654</td>\n      <td>0.226443</td>\n      <td>0.661903</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submit.to_csv('20210518_ensemble(+cat_weightX).csv',index=False)","metadata":{"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":"## torch","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n\nfrom sklearn.preprocessing import MinMaxScaler    \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# train=pd.get_dummies(train,drop_first=True)\n# test=pd.get_dummies(test,drop_first=True)","metadata":{"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"train.shape,test.shape","metadata":{"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"((26453, 18), (10000, 17))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle=LabelEncoder()\n\ntrain['gender']=le.fit_transform(train['gender'])\ntest['gender']=le.transform(test['gender'])\n\ntrain['car']=le.fit_transform(train['car'])\ntest['car']=le.transform(test['car'])\n\ntrain['reality']=le.fit_transform(train['reality'])\ntest['reality']=le.transform(test['reality'])\n\ntrain['income_type']=le.fit_transform(train['income_type'])\ntest['income_type']=le.transform(test['income_type'])\n\ntrain['edu_type']=le.fit_transform(train['edu_type'])\ntest['edu_type']=le.transform(test['edu_type'])\n\ntrain['family_type']=le.fit_transform(train['family_type'])\ntest['family_type']=le.transform(test['family_type'])\n\ntrain['house_type']=le.fit_transform(train['house_type'])\ntest['house_type']=le.transform(test['house_type'])\n\ntrain['occyp_type']=le.fit_transform(train['occyp_type'])\ntest['occyp_type']=le.transform(test['occyp_type'])","metadata":{"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"X=train.drop('credit',axis=1)\ny=train['credit']\n\nfrom sklearn.preprocessing import normalize\n\nX=normalize(X,axis=1)\ntestc=test.copy()\ntestc=normalize(testc,axis=1)","metadata":{"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=71,stratify=y)","metadata":{"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"X_tr,X_val,y_tr,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=71,stratify=y_train)","metadata":{"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"X_tr,y_tr=np.array(X_tr),np.array(y_tr)\nX_val,y_val=np.array(X_val),np.array(y_val)\nX_test,y_test=np.array(X_test),np.array(y_test)","metadata":{"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"import random\n\ndef set_seed(seed,mode=None):\n    torch.manual_seed(seed)\n    torch.backends.cudnn.deterministic=True\n    torch.backends.cudnn.benchmark=False\n    np.random.seed(seed)\n    random.seed(seed)\n    if mode=='reproductibility':\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        \nset_seed(71)\n\n# def seed_torch(seed=42):\n#     random.seed(seed)\n#     os.environ['PYTHONHASHSEED'] = str(seed)\n#     np.random.seed(seed)\n#     torch.manual_seed(seed)\n#     torch.cuda.manual_seed(seed)\n#     torch.backends.cudnn.deterministic = True\n\n# seed_torch(seed=seed_value)","metadata":{"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"class ClassifierDataset(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\ntrain_dataset = ClassifierDataset(torch.from_numpy(X_tr).float(), torch.from_numpy(y_tr).long())\nval_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\ntest_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())","metadata":{"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"target_list = []\nfor _, t in train_dataset:\n    target_list.append(t)\n    \ntarget_list = torch.tensor(target_list)\ntarget_list = target_list[torch.randperm(len(target_list))]","metadata":{"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"def get_class_distribution(obj):\n    count_dict = {\n        \"0\": 0,\n        \"1\": 0,\n        \"2\": 0\n    }\n    \n    for i in obj:\n        if i == 0: \n            count_dict['0'] += 1\n        elif i == 1: \n            count_dict['1'] += 1\n        elif i == 2: \n            count_dict['2'] += 1            \n        else:\n            print(\"Check classes.\")\n            \n    return count_dict\n\nclass_count = [i for i in get_class_distribution(y_train).values()]\nclass_weights = 1./torch.tensor(class_count, dtype=torch.float) \nprint(class_weights)","metadata":{"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"tensor([3.6510e-04, 1.8772e-04, 6.9353e-05])\n","output_type":"stream"}]},{"cell_type":"code","source":"class_weights_all = class_weights[target_list]","metadata":{"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"weighted_sampler = WeightedRandomSampler(\n    weights=class_weights_all,\n    num_samples=len(class_weights_all),\n    replacement=True\n)","metadata":{"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 300\nBATCH_SIZE = 16\nLEARNING_RATE = 0.0007\nNUM_FEATURES = len(train.columns)-1\nNUM_CLASSES = 3","metadata":{"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE,\n                          sampler=weighted_sampler\n)\nval_loader = DataLoader(dataset=val_dataset, batch_size=1)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1)","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"## softmax나 relu바꾸기. 2개 일때 괜찮은. \n## \nclass MulticlassClassification(nn.Module):\n    def __init__(self, num_feature, num_class):\n        super(MulticlassClassification, self).__init__()\n        \n        self.layer_1 = nn.Linear(num_feature, 512)\n        self.layer_2 = nn.Linear(512, 128)\n        self.layer_3 = nn.Linear(128, 64)\n        self.layer_out = nn.Linear(64, num_class) \n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.2)\n        self.batchnorm1 = nn.BatchNorm1d(512)\n        self.batchnorm2 = nn.BatchNorm1d(128)\n        self.batchnorm3 = nn.BatchNorm1d(64)\n        \n    def forward(self, x):\n        x = self.layer_1(x)\n        x = self.batchnorm1(x)\n        x = self.relu(x)\n        \n        x = self.layer_2(x)\n        x = self.batchnorm2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_3(x)\n        x = self.batchnorm3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_out(x)\n        \n        return x","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nprint(model)","metadata":{"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"MulticlassClassification(\n  (layer_1): Linear(in_features=17, out_features=512, bias=True)\n  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n  (relu): ReLU()\n  (dropout): Dropout(p=0.2, inplace=False)\n  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install torchsummary","metadata":{"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# from torchsummary import summary\n\n# summary(model,(1,47))","metadata":{"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def multi_acc(y_pred, y_test):\n    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n    \n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() / len(correct_pred)\n    \n    acc = torch.round(acc * 100)\n    \n    return acc","metadata":{"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"accuracy_stats = {\n    'train': [],\n    \"val\": []\n}\nloss_stats = {\n    'train': [],\n    \"val\": []\n}","metadata":{"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"print(\"Begin training.\")\nEPOCHS=10\nfor e in tqdm(range(1, EPOCHS+1)):\n    \n    # TRAINING\n    train_epoch_loss = 0\n    train_epoch_acc = 0\n    model.train()\n    for X_train_batch, y_train_batch in train_loader:\n        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_train_pred = model(X_train_batch)\n        \n        train_loss = criterion(y_train_pred, y_train_batch)\n        train_acc = multi_acc(y_train_pred, y_train_batch)\n        \n        train_loss.backward()\n        optimizer.step()\n        \n        train_epoch_loss += train_loss.item()\n        train_epoch_acc += train_acc.item()\n        \n        \n    # VALIDATION    \n    with torch.no_grad():\n        \n        val_epoch_loss = 0\n        val_epoch_acc = 0\n        \n        model.eval()\n        for X_val_batch, y_val_batch in val_loader:\n            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n            \n            y_val_pred = model(X_val_batch)\n                        \n            val_loss = criterion(y_val_pred, y_val_batch)\n            val_acc = multi_acc(y_val_pred, y_val_batch)\n            \n            val_epoch_loss += val_loss.item()\n            val_epoch_acc += val_acc.item()\n    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n\n\n    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n","metadata":{"trusted":true},"execution_count":92,"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Begin training.\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:12<01:56, 12.92s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 001: | Train Loss: 1.09673 | Val Loss: 1.06675 | Train Acc: 54.625| Val Acc: 61.805\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [00:15<02:22, 15.78s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-60874e6f6959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-5d63d3fdec13>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m     )\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Create dataframes\ntrain_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\ntrain_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n# Plot the dataframes\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\nsns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\nsns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_list = []\nwith torch.no_grad():\n    model.eval()\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n        y_pred_list.append(y_pred_tags.cpu().numpy())\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","metadata":{"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"idx2class={0:0,1:1,2:2}\n\nconfusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred_list)).rename(columns=idx2class, index=idx2class)\n\nsns.heatmap(confusion_matrix_df,annot=True)","metadata":{"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAWcAAAD6CAYAAAB9N4akAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfHUlEQVR4nO3deXgV9fXH8fe5SdhlEyEhiQYBFVxARcS1UDUBFXFFUJAqLbaAQOuGYl2wqC2I1dbSH1YqVQRxBRGRxb1VFpEiqwRRSUhYBQUqkOT7+yNDvJDtBm5yJ8Pn9TzzcO935t45kwcOJ2e+M2POOURExF9CsQ5ARESKU3IWEfEhJWcRER9SchYR8SElZxERH1JyFhHxISVnEZESmFmqmb1nZivMbLmZDfXGHzSzbDNb4i2Xhn3mHjPLNLPVZpYRNt7VG8s0s+ER7b+y5znH10jWRGoJhEuanRbrEALv7fVv2+F+x74tX0WccxKaHF/q/swsCUhyzi02s6OAz4ArgZ7ATufcmIO2bwtMBjoCzYG5wAne6i+BS4AsYCHQ2zm3oqzY4iM9CBGRaqEgPypf45zLAXK81z+Y2UoguYyP9ACmOOf2AOvMLJPCRA2Q6Zz7CsDMpnjblpmc1dYQkWBxBZEvETKzNOB0YL43NNjMlprZBDNr5I0lA+vDPpbljZU2XiYlZxEJloKCiBczG2Bmi8KWAQd/nZnVA14FhjnnvgfGAS2B9hRW1o9XxmGorSEigeIqUBE758YD40tbb2YJFCbmSc6517zPbAxb/wwww3ubDaSGfTzFG6OM8VKpchaRYMnPi3wpg5kZ8Cyw0jk3Nmw8KWyzq4Bl3uvpQC8zq2lmLYDWwAIKTwC2NrMWZlYD6OVtWyZVziISLFE6IQicB/QFvjCzJd7YvUBvM2sPOOBr4FYA59xyM5tK4Ym+PGCQcy4fwMwGA+8AccAE59zy8nauqXQiEdJUusoXjal0e79eFHHOqZHW4bD3V1lUOYtIsBRE3nP2MyVnEQmUipwQ9DMlZxEJFlXOIiI+lL8v1hFEhZKziASL2hoiIj6ktoaIiA+pchYR8SFVziIi/uMKdEJQRMR/VDmLiPiQes4iIj4UvRsfxZSSs4gEiypnEREfUs9ZRMSHyrmJfnWh5CwiwaLKWUTEf7yHj1R7Ss4iEiyqnEVEfEizNUREfEiVs4iID2m2hoiID6mtISLiQ2priIj4kJJz8GSkd2bs2JHEhUJM+Odk/jT66ViHFDg1a9bk/XdfpUbNmsTHx/Haa2/x0MjHYx2Wb4RCIZ566ym25G7hwZsfPGDdMc2P4fYnbqde/XqE4kL889F/svC9hYe1v2apzRj+9HDqN6rPmi/WMGboGPL25XHVr66ia6+u5Ofns2PrDp644wk2ZW86rH1VmYC0NUKxDsAvQqEQTz05isu79+HUdl24/voradOmdazDCpw9e/ZwcXpPzuxwCWd2SCcjvTNndzwj1mH5Ro/+Pfg289sS1/Ue0puPZnzE4G6DeWzQYwwaNSji7734uou58bc3Fhu/5Z5beOMfb9D/gv7s3L6TjF4ZAKxdtpYhlw1hYPpAPp75MbeMuOXQDigW8vMiX3xMydnT8azTWbv2a9at+5Z9+/Yxdeo0ruieEeuwAmnXrt0AJCTEE5+QgHMuxhH5Q5PEJnT8eUfemfxOieudc9SpVweAOkfVYevGrUBhYdF/RH+enPEkf5v9N7rd2C3ifbY7rx0fvfURAHNfmcs5GecAsPSTpez5cQ8Aqxavoklik0M+ripXUBD54mPltjXM7CSgB5DsDWUD051zKyszsKrWPDmR9Vkbit5nZefQ8azTYxhRcIVCIRbMn0WrlmmM+/tzLFj4eaxD8oVbH7yVZx95ltp1a5e4/oUnXmDUpFFccfMV1Kxdk3tvuBeAjF4Z7PphF0MvH0pCjQTGvD6GxR8uZuP6jWXur36j+uz6fhcF+YVJakvOFo5OPLrYdum90ln0/qLDPLoqFJC2RpnJ2czuBnoDU4AF3nAKMNnMpjjnHqvk+CSACgoK6HBWOg0a1OfVl5/l5JNPZPny1bEOK6Y6XtSR7Vu3k/lFJqd2OrXEbTr36Mzcl+fy2vjXOOmMk7jzz3fy64t/zRkXnkFamzTOv/R8AOoeVZfkFsns/mE3j055FICjGh5FfEJ8UWU8ZtgYtm3cVm5cXa7qwgmnncBd190VpSOtAj6viCNVXuXcHzjZOXfAExPNbCywHCgxOZvZAGAAgMU1IBSqG4VQK9eG7FxSU5oXvU9JTmLDhtwYRhR8O3Z8z/sf/JuM9M5HfHJu26EtnS7pxFldziKhZgJ1jqrDnU/eyeiho4u2ybg+g/v63gcUthoSaiZQv3F9MBh3/zgWf7C42PcO7joYKOw5N0tpxqQnJh2wvm79uoTiQhTkF9AkqQlbc7cWrWt/fnt63daLu667i317q9FDUwOSnMvrORcAzUsYT/LWlcg5N94518E516E6JGaAhYuW0KpVC9LSUklISKBnzx68OWN2rMMKnCZNGtOgQX0AatWqxcUXXcjq1WtjHFXsPffH5+jbsS+/OPcXPDboMf777/8ekJgBNm3YRPvz2wOQ2iqVGrVqsGPrDhZ/sJjL+l5GXHwcAMktkqlZu2ZE+136n6VccNkFAFx87cV8MvsTAFqe3JIhjw3hoVseYsfWHVE6yiriXOSLj5VXOQ8D5pnZGmC9N3Ys0AoYXIlxVbn8/HyGDruPmW+9SFwoxHMTX2LFii9jHVbgJCU1Y8KzfyYuLkQoFOKVV97krZlzYx2Wb/W9vS9fLv2S+XPm84+H/8GQPw7hql9ehXOOsb8bC8CsybNomtqUv7z9F8yMHVt3MPKXIyP6/gmPTmD408O56c6bWLtsLbOnFBYk/Uf0p1adWtz798K+9uYNm3nolocq5yCjLc/fszAiZeWdKTezENCRA08ILnQR3jQ1vkayv/97EonQJc1Oi3UIgff2+rftcL/jfy+MiDjn1O4z6rD3V1nKna3hnCsAPq2CWEREDt8R0nMWEaleotRzNrNUM3vPzFaY2XIzG+qNNzazOWa2xvuzkTduZvaUmWWa2VIzOyPsu/p5268xs36RHIaSs4gES/QuQskDbnfOtQU6AYPMrC0wHJjnnGsNzPPeA3QDWnvLAGAcFCZz4AHgbApbxA/sT+hlUXIWkWCJUnJ2zuU45xZ7r38AVlJ47q0HMNHbbCJwpfe6B/AvV+hToKGZJQEZwBzn3Dbn3HfAHKBreYehGx+JSKC4/Og/4NXM0oDTgflAM+dcjrcqF2jmvU7mp1ltAFneWGnjZVLlLCLBUoHK2cwGmNmisGXAwV9nZvWAV4Fhzrnvw9e5wululTIjTZWziARLBe6t4ZwbD4wvbb2ZJVCYmCc5517zhjeaWZJzLsdrW+y/l2o2kBr28RRvLBvofND4++XFpspZRIKlwEW+lMHMDHgWWOmcGxu2ajqwf8ZFP2Ba2PhN3qyNTsAOr/3xDpBuZo28E4Hp3liZVDmLSLBEb57zeUBf4AszW+KN3UvhPYWmmll/4Bugp7duJnApkAnsBm4GcM5tM7OHgf1PRhjpnCv3rlNKziISLFE6Ieic+xgo7QrCi0rY3gElPgHBOTcBmFCR/Ss5i0iwBOQKQSVnEQmWcnrJ1YWSs4gEy5HwJBQRkWpHlbOIiP849ZxFRHyoEi7fjgUlZxEJFrU1RER8SG0NEREfUuUsIuJDmkonIuJDqpxFRPzH5Wm2hoiI/6hyFhHxIfWcRUR8SJWziIj/OCVnEREf0glBEREfUuUsIuJDSs4iIv5T+Ci/6k/JWUSCRZWziIgPKTmLX5T27HaJrks5OtYhSARcni5CERHxn2DkZiVnEQkWXYQiIuJHSs4iIj6ktoaIiP+orSEi4kMuT8lZRMR/1NYQEfGfgNxrX8lZRAJGyVlExH9UOYuI+JDLi3UE0RGKdQAiItHkCiJfymNmE8xsk5ktCxt70MyyzWyJt1watu4eM8s0s9VmlhE23tUbyzSz4ZEch5KziARKNJMz8BzQtYTxJ5xz7b1lJoCZtQV6ASd7n/mbmcWZWRzwNNANaAv09rYtk9oaIhIsLnr3aXTOfWhmaRFu3gOY4pzbA6wzs0ygo7cu0zn3FYCZTfG2XVHWl6lyFpFAiXLlXJrBZrbUa3s08saSgfVh22R5Y6WNl0nJWUQCxRVYxIuZDTCzRWHLgAh2MQ5oCbQHcoDHK+M41NYQkUApyI+8reGcGw+Mr8j3O+c27n9tZs8AM7y32UBq2KYp3hhljJdKlbOIBEpltzXMLCns7VXA/pkc04FeZlbTzFoArYEFwEKgtZm1MLMaFJ40nF7eflQ5i0iguILonRA0s8lAZ6CJmWUBDwCdzaw94ICvgVsBnHPLzWwqhSf68oBBzrl873sGA+8AccAE59zy8vat5CwigeKieFM651zvEoafLWP7UcCoEsZnAjMrsm8lZxEJlGhWzrGk5CwigVKRE4J+puQsIoGiyllExIdcFK8QjCUlZxEJFN0yVETEhwpUOYuI+I/aGiIiPqTZGiIiPqTZGiIiPqSes4iIDwWl56y70oXJSO/M8mUfsmrFx9x156BYhxMYz4x/nOys//L55/OKrRs27Fb27c3m6KMblfDJI0+7WzK4Ye6j3DD3Mdr1zyi2vkX6GfSe/Qi9Zo2i51sjSTrrhMPeZ82Gdekx6W76fjiGHpPupmaDOgCccOW59J79CL3nPMq1r99PkzbHHva+qoJzkS9+puTsCYVCPPXkKC7v3odT23Xh+uuvpE2b1rEOKxAm/msql19+Y7HxlJTmXHLxhXzzTVYMovKfxiemcPINnZl6+QNMzriXFhedToO0Zgdsk/Xxcian38uUriOYd/szXPSnX0b8/cmd2nDx2OL3kj9zYHey/r2C5y+8g6x/r+DMgd0B+H79Zl677g9MvuQeFj75Bl3+eMvhHWAVKXAW8eJnSs6ejmedztq1X7Nu3bfs27ePqVOncUX34pWLVNzHH89n23fbi42PGfMg99w7Cuf3EqaKNG7VnNzP15L3415cfgHZ81fRsmuHA7bZt3tP0euEOjUP+Nmdfutl9Jwxkt6zH+Hs310d8X6PTz+Tla98BMDKVz7i+IzCfeZ+toY9O3YXvv48k3pJjQ/52KpSQYFFvPjZISdnM7s5moHEWvPkRNZnbSh6n5WdQ/PmiTGMKNi6d09nQ3YOS5eW+YzLI8rW1Vk073gitRrWI75WDY7r0o56zY8utt3xXTvQ570/0X3iHcy74xkAUi88hYYtmjH18vuZnDGCY05tQfOzT4xov3Wa1Gf3pu0A7N60nTpN6hfbpm2vznzz3tJDP7gqFJTK+XBOCD4E/LOkFd5zuAYAWFwDQqG6h7EbCZratWsx/O7b6HbpDbEOxVe+y9zA4r/NoMeku9n3vz1sWfENLr/4tchfzVrEV7MW0fzsE+l0x7W8ccNjHHvhqRx74an0mlV4K+GEurVomJbIhvmruW76g8TVSCChbi1qNaxbtM1/Hp3Ctx98Uez7D/5FJvmcNrS9/me8evXDUT/myhCUE4JlJmczK+2/SgOalbLugOdyxddIrha/s27IziU1pXnR+5TkJDZsyI1hRMHVsmUaaWnH8tmiOQCkpCSxYP47nHveZWzcuDnG0cXWipc+YMVLHwBwzt092ZmzrdRtN8xfTf1jm1KrUT3MjEVPv8nySe8W2+7lKx4ECnvObXpewNzfHfjIvN1bvqdO04aFVXPThvxv6/dF644+KZWLRv+S6X1H8+P2nVE4wsrn94o4UuW1NZoBNwHdS1i2Vm5oVWvhoiW0atWCtLRUEhIS6NmzB2/OmB3rsAJp2bJVJKe0o/UJnWh9QieysnLoeHbGEZ+YAWofXdhSqNf8aFp27cDqN/5zwPrwE4THnJJGXM14fvxuJ998sJS2119IQp2aANRNbFT0XeVZN2cxba69AIA2117AV7M/K4rh0meGMXvo39m+rvoUKq4Ci5+V19aYAdRzzi05eIWZvV8ZAcVKfn4+Q4fdx8y3XiQuFOK5iS+xYsWXsQ4rEJ5//ml+duE5NGnSmHVfLWLkyDH887kpsQ7Lly4dP5RaDetRkJfH+/dNZO/3uzmlz88BWPbCu7TsdhYnXXM+BXn55P24l1kD/wrA+g+X0bhVMtdOexCAfbt+ZPbQcQdUwaX57Ok36TruNtr2+hk/ZG3h7YF/AaDjsKuo1bAenUf9AoCC/HymXnZ/9A86yvILgjHPwSr7THl1aWtUZ8H4Jc7/xjbrEusQAu+29S8c9l/njxKvjTjnXJD7im//+egKQREJFBeQckXJWUQCpSAgv6srOYtIoBSochYR8R+1NUREfChfyVlExH8C8nxXJWcRCRYlZxERH1LPWUTEh3x+J9CIKTmLSKBoKp2IiA/lxzqAKFFyFpFAKTBVziIivhOQq7eVnEUkWIIylS4YNz4VEfEUWORLecxsgpltMrNlYWONzWyOma3x/mzkjZuZPWVmmWa21MzOCPtMP2/7NWbWL5LjUHIWkUDJxyJeIvAc0PWgseHAPOdca2Ce9x6gG9DaWwYA46AwmQMPAGcDHYEH9if0sig5i0igRLNyds59CBz8IMcewETv9UTgyrDxf7lCnwINzSwJyADmOOe2Oee+A+ZQPOEXo56ziARKFfScmznncrzXufz0sOtkYH3YdlneWGnjZVLlLCKBUpEHvJrZADNbFLYMqNC+Cp/zVykTRFQ5i0igVOTybefceGB8BXex0cySnHM5XttikzeeDaSGbZfijWUDnQ8af7+8nahyFpFAKajAcoimA/tnXPQDpoWN3+TN2ugE7PDaH+8A6WbWyDsRmO6NlUmVs4gESn4ULxA0s8kUVr1NzCyLwlkXjwFTzaw/8A3Q09t8JnApkAnsBm4GcM5tM7OHgYXediOdcwefZCxGyVlEAiWaJwSdc71LWXVRCds6YFAp3zMBmFCRfSs5i0igBOUKQSVnEQkU3VtDRMSHdLN9EREfUltDRMSHdLN9EREfUltDRMSH1NYQEfEhzdYQ37CAPDPN7379+chYhyARKAhIelZyFpFA0QlBEREfUs9ZRMSHNFtDRMSH1HMWEfGhYKRmJWcRCRj1nEVEfCg/ILWzkrOIBIoqZxERH9IJQRERHwpGalZyFpGAUVtDRMSHdEJQRMSH1HMWEfGhYKRmJWcRCRhVziIiPqQTgiIiPuRUOYuI+I9ma4iI+JDaGiIiPlTgVDmLiPhOMFKzkrOIBIym0omI+JBma4iI+FCekrOIiP8EpXIOxToAEZFoKqjAUh4z+9rMvjCzJWa2yBtrbGZzzGyN92cjb9zM7CkzyzSzpWZ2xuEch5KziASKcy7iJUJdnHPtnXMdvPfDgXnOudbAPO89QDegtbcMAMYdznEoOYtIoBTgIl4OUQ9govd6InBl2Pi/XKFPgYZmlnSoO1FyFpFAycdFvETAAbPN7DMzG+CNNXPO5Xivc4Fm3utkYH3YZ7O8sUOiE4IiEigVqYi9hDsgbGi8c2582PvznXPZZtYUmGNmq8I/75xzZlYpZyCVnEUkUCrQS8ZLxOPLWJ/t/bnJzF4HOgIbzSzJOZfjtS02eZtnA6lhH0/xxg6J2hphMtI7s3zZh6xa8TF33Tko1uEERkpKErPfmcp/l7zLks/nMXhwfwAaNWrIzJkvsnz5R8yc+SINGzaIcaSxlbNxMzcPvpsrbhxAjxtv5fmpbxTbZsHipXRKv4Zr+g3imn6DGDdh0mHvd+/evdz++0fp1vMWev9qGNk5GwH4YsXqov1c3W8gcz/492HvqypEa7aGmdU1s6P2vwbSgWXAdKCft1k/YJr3ejpwkzdroxOwI6z9UWFWkf9lDkV8jeRqMekwFAqxcvlHdL20N1lZOXz6yUz69B3IypVrYh1auUJmsQ6hTImJTUlMbMqSJcuoV68u8z99m2uv7c9NN/Vk27btjB7zNHfeMYhGjRpw74hHYh1uqXZlf1ip3795yzY2b91G2xNbsWvXbnr2H8JTj/6eli2OK9pmweKlPDf5Vf42+qEKf392zkZGjHqc5/76pwPGp7w2g9WZ63jgrtuYOfd95n3wCY8/fA//+/FHEuITiI+PY/OWbVzTbyDvTptEfHzcYR9raRKaHH/Yf5nTU7tGnHNmr59V6v7M7Hjgde9tPPCic26UmR0NTAWOBb4BejrntpmZAX8FugK7gZudc4sO8TDU1tiv41mns3bt16xb9y0AU6dO44ruGdUiOftdbu4mcnMLf/PbuXMXq1atoXlyIt27p3PxJdcB8PwLLzN3zsu+Ts6V7ZgmjTmmSWMA6tatw/HHpbJx89YDknNZ3nznXSa9PI19+/I47eQTue/2QcTFlZ9I3/3oEwb27wNAeucLeGTsOJxz1K5Vq2ibPXv3gs+LgP2idW8N59xXQLsSxrcCF5Uw7oCo/cpdblvDzE4ys4vMrN5B412jFYQfNE9OZH3WhqL3Wdk5NG+eGMOIgum441Jo1+4UFiz4nKZNmxQl7dzcTTRt2iTG0flHds5GVq5Zy2knn1hs3X+XreTqfgP59e2/J/OrbwBY+/W3zJr3Ac///XFenfg0oVCIGbPfi2hfmzZvJdH72cfHx1Gvbh227/gegKXLV9Hjxlu56qbfcP+dgyu1ao6WfFcQ8eJnZVbOZjaEwv8JVgLPmtlQ59z+/sojwKxKjk8CpG7dOrw0ZTx33PEgP/yws9j6ym6xVRe7d/+P3474A3cPuZV6desesK7tiS2Z8+pE6tSpzYf/WcCQe0Yy86Vnmb9oCStWZdKr/1AA9uzZQ+NGDQEYcs9IsjdsZF/ePnI2buaafoXFXZ+ePbjqsvQyYznt5JOYNun/WPv1t4z4w+Nc0OksatasEf2DjqKgXL5dXlvjV8CZzrmdZpYGvGJmac65J4GyejVF01MsrgGhUN3SNvWNDdm5pKY0L3qfkpzEhg25MYwoWOLj43nppfFMnvI6b0x7G4BNm7aQmNiU3NxNJCY2ZfPmrTGOMvb25eUxbMQfuCy9C5d0Pq/Y+vBkfeG5HfnD40/z3fYdOOe4otvF/PY3Nxf7zFOP3g+U3nNueszR5G7aQmLTY8jLy2fnrt00bFD/gG1aph1Lndq1WfPV15zS5oRoHGqlCcrN9stra4ScczsBnHNfA52BbmY2ljKSs3NuvHOug3OuQ3VIzAALFy2hVasWpKWlkpCQQM+ePXhzxuxYhxUY4/9vDKtWZfLkk88Ujb05Yw59+xT2nPv2uY433zyyf97OOe5/9M8cf1wq/XpdXeI2W7ZuK/oN44sVqylwjoYN6tOpQ3vmvP8xW7/bDsCO739gQ+7GiPbb5fxOTJs5F4DZ73/E2We2w8zI2pBLXl4+ABtyN7Lum/UkJzUr66t8wVVg8bPyKueNZtbeObcEwKugLwcmAKdWdnBVKT8/n6HD7mPmWy8SFwrx3MSXWLHiy1iHFQjnnnsWffpcyxdfrGThgncA+P39f2T06L/y4ot/5xc39+Lbb7O44YbfxDjS2Pp86XLenDWP1i3TiloPQ2/tR87GzQBcf9VlzH7vY156/S3i4uOoVaMGox8ajpnRssVx3ParmxgwbAQFroCE+HhG/G4gzRPLT6ZXX57BPQ+PplvPW2hQ/yhGP1R4q4jFS5fz7PNTiY+PJxQy7rtjEI2qwXTHoNxsv8ypdGaWAuQ554r9fm9m5znnyp34WF2m0lVnfp9KFxSVPZVOojOV7pzkLhHnnE+y3/PtP54yK2fnXFYZ66rHjHQROaL4fRZGpDTPWUQC5UiZrSEiUq0EZUqmkrOIBEpQTggqOYtIoKhyFhHxofyIng7of0rOIhIoQblCUMlZRAJFszVERHxIlbOIiA+pchYR8SFVziIiPqTLt0VEfEhtDRERH3KqnEVE/EeXb4uI+JAu3xYR8SFVziIiPpRfoJ6ziIjvaLaGiIgPqecsIuJD6jmLiPiQKmcRER/SCUERER9SW0NExIfU1hAR8SHdMlRExIc0z1lExIeCUjmHYh2AiEg0FbiCiJfymFlXM1ttZplmNrwKwi+iyllEAiVaJwTNLA54GrgEyAIWmtl059yKqOygHKqcRSRQnHMRL+XoCGQ6575yzu0FpgA9Kv0APErOIhIorgJLOZKB9WHvs7yxKlHpbY28vdlW2fuINjMb4JwbH+s4gkw/48p3pP6MK5JzzGwAMCBsaLxffmaqnEs2oPxN5DDpZ1z59DMuh3NuvHOuQ9gSnpizgdSw9yneWJVQchYRKdlCoLWZtTCzGkAvYHpV7VyzNURESuCcyzOzwcA7QBwwwTm3vKr2r+RcMl/0nAJOP+PKp5/xYXLOzQRmxmLfFpSbhIiIBIl6ziIiPqTkHCaWl2oeKcxsgpltMrNlsY4lqMws1czeM7MVZrbczIbGOiapOLU1PN6lml8Sdqkm0LuqLtU8UpjZhcBO4F/OuVNiHU8QmVkSkOScW2xmRwGfAVfq73L1osr5JzG9VPNI4Zz7ENgW6ziCzDmX45xb7L3+AVhJFV7ZJtGh5PyTmF6qKVIZzCwNOB2YH+NQpIKUnEUCyszqAa8Cw5xz38c6HqkYJeefxPRSTZFoMrMEChPzJOfca7GORypOyfknMb1UUyRazMyAZ4GVzrmxsY5HDo2Ss8c5lwfsv1RzJTC1Ki/VPFKY2WTgE+BEM8sys/6xjimAzgP6Aj83syXecmmsg5KK0VQ6EREfUuUsIuJDSs4iIj6k5Cwi4kNKziIiPqTkLCLiQ0rOIiI+pOQsIuJDSs4iIj70/4rAxHgms0e7AAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}